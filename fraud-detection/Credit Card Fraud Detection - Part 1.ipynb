{"cells":[{"cell_type":"markdown","source":["# Cosmos DB in Fabric\n","# Credit Card Fraud Detection Sample – Part 1: Data Generation\n","\n","This section demonstrates how to generate synthetic credit card data and transactions for use in a Cosmos DB container within Microsoft Fabric. The goal is to create realistic sample data that can later be used for fraud detection scenarios."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b34b0686-fe1b-4f00-9d26-0e6a7e1e8de7"},{"cell_type":"markdown","source":["### Prerequisites\n","Before running this notebook, ensure you have:\n","\n","- A **Cosmos DB artifact** created in Microsoft Fabric.\n","- Two containers:\n","    - **CCTransactions** – Stores credit card transaction records. \n","        Indexing Policy\n","        {\n","        \"path\": \"/embedding\",\n","        \"type\": \"DiskANN\",\n","        \"dimensions\": 1536,\n","        \"metric\": \"cosine\",\n","        \"quantizationByteSize\": 4,\n","        \"indexingSearchListSize\": 128,\n","        \"vectorIndexShardKey\": [\"/card_id\"]\n","        }\n","        data type: float 32\n","    - **CreditCards** – Stores credit card details.\n"," \n","- An **OpenAI endpoint and key** for generating embeddings (placeholders will be used in this sample).\n","- Installed required Python packages."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1aef7272-855a-41f0-ae77-366023ea411a"},{"cell_type":"markdown","source":["### Install Required Packages ###"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"add8b489-8f3d-4880-b71d-1cbca7050b8c"},{"cell_type":"code","source":["%pip install azure-core azure-cosmos\n","%pip install openai"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[3,4,5,6,7,8],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3514703Z","session_start_time":"2025-11-12T10:03:18.3518311Z","execution_start_time":"2025-11-12T10:03:32.133302Z","execution_finish_time":"2025-11-12T10:05:19.2135255Z","parent_msg_id":"f1a7d9a7-64a6-44a4-ad5e-44a35fbf76b2"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: azure-core in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (1.30.2)\nCollecting azure-cosmos\n  Downloading azure_cosmos-4.14.1-py3-none-any.whl.metadata (104 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-core) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-core) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-core) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core) (2024.2.2)\nDownloading azure_cosmos-4.14.1-py3-none-any.whl (386 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.1/386.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: azure-cosmos\nSuccessfully installed azure-cosmos-4.14.1\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nCollecting openai\n  Downloading openai-2.7.2-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.8.0)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting jiter<1,>=0.10.0 (from openai)\n  Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nCollecting pydantic<3,>=1.9.0 (from openai)\n  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.65.0)\nCollecting typing-extensions<5,>=4.11 (from openai)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: idna>=2.8 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: certifi in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nCollecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nCollecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\nDownloading openai-2.7.2-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nInstalling collected packages: typing-extensions, jiter, h11, annotated-types, typing-inspection, pydantic-core, httpcore, pydantic, httpx, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages, outside environment /nfs4/pyenv-f1453685-9958-4453-8f59-e92a7317c6d9\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnni 3.0 requires filelock<3.12, but you have filelock 3.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed annotated-types-0.7.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 openai-2.7.2 pydantic-2.12.4 pydantic-core-2.41.5 typing-extensions-4.15.0 typing-inspection-0.4.2\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"48a7b010-bd48-4488-985a-af425176a828"},{"cell_type":"markdown","source":["### Imports and Configuration ###\n","\n","Set up imports and define configuration values for Cosmos DB and OpenAI. Replace placeholder strings with your actual values when running in your environment."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0d1dab07-9a9d-4004-baf1-7c32d4e9a2df"},{"cell_type":"code","source":["# Imports\n","import base64, json\n","import openai\n","import os\n","import uuid\n","import random\n","import time\n","import math\n","import numpy as np\n","from datetime import datetime, timezone\n","from typing import Any, Optional, List, Dict, Tuple\n","\n","from azure.cosmos import CosmosClient, PartitionKey, ThroughputProperties\n","from azure.core.credentials import TokenCredential, AccessToken\n","\n","# Cosmos DB configuration\n","COSMOS_ENDPOINT = '<COSMOS_ENDPOINT>' # The Cosmos DB artifact endpoint from the artifact settings\n","COSMOS_DATABASE_NAME = '<COSMOS_DATABASE_NAME>' # The Cosmos DB artifact name is the database name\n","COSMOS_TRANSACTION_CONTAINER_NAME = \"CCTransactions\"\n","COSMOS_CC_CONTAINER_NAME = \"CreditCards\"\n","\n","# OpenAI configuration\n","os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n","\n","OPEN_AI_MODEL = \"text-embedding-ada-002\"\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3511178Z","session_start_time":null,"execution_start_time":"2025-11-12T10:05:27.9843572Z","execution_finish_time":"2025-11-12T10:05:38.6784843Z","parent_msg_id":"a0e7c176-ae73-4178-8fe9-02f4445b6ad3"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8b2b5831-10a3-4dde-ab11-87f71bc4e9d6"},{"cell_type":"markdown","source":["### Authentication Class ###\n","\n","Use a custom credential class to authenticate securely with Cosmos DB using Fabric tokens."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b104b39-f9f1-4a37-8ec2-4aca01b70c09"},{"cell_type":"code","source":["## Authentication Class\n","\n","class FabricTokenCredential(TokenCredential):\n","    \"\"\"Token credential for Fabric Cosmos DB access with automatic refresh and retry logic.\"\"\"\n","    \n","    def get_token(self, *scopes: str, claims: Optional[str] = None, tenant_id: Optional[str] = None,\n","                  enable_cae: bool = False, **kwargs: Any) -> AccessToken:\n","        access_token = notebookutils.credentials.getToken(\"https://cosmos.azure.com/.default\")\n","        parts = access_token.split(\".\")\n","        if len(parts) < 2:\n","            raise ValueError(\"Invalid JWT format\")\n","        payload_b64 = parts[1]\n","        # Fix padding\n","        padding = (-len(payload_b64)) % 4\n","        if padding:\n","            payload_b64 += \"=\" * padding\n","        payload_json = base64.urlsafe_b64decode(payload_b64.encode(\"utf-8\")).decode(\"utf-8\")\n","        payload = json.loads(payload_json)\n","        exp = payload.get(\"exp\")\n","        if exp is None:\n","            raise ValueError(\"exp claim missing in token\")\n","        return AccessToken(token=access_token, expires_on=exp)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3527989Z","session_start_time":null,"execution_start_time":"2025-11-12T10:05:38.6805383Z","execution_finish_time":"2025-11-12T10:06:31.6821338Z","parent_msg_id":"0288e5d6-8dc3-4c70-86af-9ac4032bade0"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"822672c9-f287-4df8-be4b-92c17668fb1d"},{"cell_type":"markdown","source":["### Initialize Cosmos DB Clients ###\n","\n","Create clients for the database and containers."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7b3035ae-f70b-4276-9c4b-5e7caff1b9f5"},{"cell_type":"code","source":["# Initialize Cosmos DB cosmos client\n","COSMOS_CLIENT = CosmosClient(COSMOS_ENDPOINT, FabricTokenCredential())\n","\n","# Initialize Cosmos DB database client\n","DATABASE_CLIENT = COSMOS_CLIENT.get_database_client(COSMOS_DATABASE_NAME)\n","\n","# Intialize Cosmos DB container client\n","txns_container = DATABASE_CLIENT.get_container_client(COSMOS_TRANSACTION_CONTAINER_NAME) \n","cards_container = DATABASE_CLIENT.get_container_client(COSMOS_CC_CONTAINER_NAME)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3542313Z","session_start_time":null,"execution_start_time":"2025-11-12T10:06:31.6840964Z","execution_finish_time":"2025-11-12T10:07:17.7309313Z","parent_msg_id":"b7de76fb-1620-491d-8873-7286b8babc36"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f4a75d9a-fb95-4a12-b2b8-62a8e9d93297"},{"cell_type":"markdown","source":["### Merchant and Location Data ###\n","\n","Define sample merchants and U.S. states for transaction generation."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7bb9bcce-6d0c-470c-8fe0-4370d76bdd90"},{"cell_type":"code","source":["merchants = [\n","    # Retail & E-Commerce\n","    \"Amazon\", \"Walmart\", \"Target\", \"Best Buy\", \"Costco\", \"Home Depot\", \"Lowe's\",\n","    \"Macy's\", \"Nordstrom\", \"Kohl's\", \"eBay\", \"Wayfair\", \"Etsy\", \"AliExpress\", \"Shein\",\n","    \"Sam's Club\", \"BJ's Wholesale\", \"Bed Bath & Beyond\",\n","\n","    # Food & Beverage\n","    \"Starbucks\", \"Dunkin'\", \"McDonald's\", \"Subway\", \"Chipotle\", \"Panera Bread\",\n","    \"Domino's Pizza\", \"Pizza Hut\", \"Chick-fil-A\", \"Burger King\", \"Taco Bell\",\n","    \"KFC\", \"Popeyes\", \"Shake Shack\", \"Five Guys\",\n","\n","    # Tech & Electronics\n","    \"Apple Store\", \"Microsoft\", \"Google\", \"Samsung\", \"Dell\", \"HP\", \"Lenovo\",\n","    \"Sony\", \"Asus\", \"Acer\", \"Nvidia\",\n","\n","    # Fashion & Sports\n","    \"Nike\", \"Adidas\", \"Under Armour\", \"Lululemon\", \"Zara\", \"H&M\", \"Gap\",\n","    \"Old Navy\", \"Uniqlo\", \"Forever 21\", \"Victoria's Secret\",\n","\n","    # Entertainment & Streaming\n","    \"Netflix\", \"Hulu\", \"Disney+\", \"Spotify\", \"YouTube Premium\", \"Amazon Prime Video\",\n","    \"HBO Max\", \"Peacock\", \"Paramount+\", \"Apple TV+\", \"Crunchyroll\",\n","\n","    # Travel & Transport\n","    \"Uber\", \"Lyft\", \"Airbnb\", \"Expedia\", \"Booking.com\", \"Delta Airlines\",\n","    \"United Airlines\", \"American Airlines\", \"Southwest Airlines\", \"Marriott\",\n","    \"Hilton\", \"Hyatt\",\n","\n","    # Financial & Services\n","    \"PayPal\", \"Venmo\", \"Stripe\", \"Square\", \"Cash App\", \"Zelle\",\n","\n","    # Grocery & Pharmacy\n","    \"Kroger\", \"Safeway\", \"Albertsons\", \"Publix\", \"Trader Joe's\", \"Whole Foods\",\n","    \"CVS\", \"Walgreens\", \"Rite Aid\",\n","\n","    # Home & Lifestyle\n","    \"IKEA\", \"Ashley Furniture\", \"Crate & Barrel\", \"Williams Sonoma\",\n","\n","    # Luxury & Jewelry\n","    \"Tiffany & Co.\", \"Cartier\", \"Rolex\", \"Gucci\", \"Louis Vuitton\", \"Prada\"\n","]\n","\n","US_STATES = [\n","    \"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\n","    \"Hawaii\",\"Idaho\",\"Illinois\",\"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\n","    \"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\n","    \"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\"Rhode Island\",\n","    \"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\n","    \"Wisconsin\",\"Wyoming\"\n","]\n","\n","# Weights per your formula\n","W_AMOUNT   = 0.2\n","W_MERCHANT = 0.3\n","W_LOCATION = 0.5"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3556307Z","session_start_time":null,"execution_start_time":"2025-11-12T10:07:17.7330162Z","execution_finish_time":"2025-11-12T10:07:30.2109445Z","parent_msg_id":"a936d96a-0544-4c1a-80af-7a6495072886"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5f20a59e-a928-408e-a3c3-181178787a18"},{"cell_type":"markdown","source":["### Embedding Helpers & Transaction Generation ###\n","\n","This section adds utilities to **embed merchant, location, and amount signals,** compose them into a single vector, and **insert synthetic transactions** into the CCTransactions container. It also includes helpers to create **customer spending profiles, credit cards, and a bulk generator** for customers and transactions.\n","\n","#### Embedding Helper\n","Wraps a call to the embeddings API and returns a NumPy vector."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"16e016e2-a178-4915-857b-34acaa422f86"},{"cell_type":"markdown","source":["**What it does**\n","\n","- Calls the embeddings endpoint with OPEN_AI_MODEL and returns float32 vectors.\n","- Keeps the function general so you can reuse it for merchants, locations, or any other categorical signal.\n","\n","**Why this matters**\n","\n","- Embeddings allow you to numerically represent text features (e.g., “Nike”, “California”) so they can be compared, clustered, or used downstream in anomaly detection."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e2613684-31c2-456e-9fcf-352c954c76b5"},{"cell_type":"code","source":["\n","# ─────────────────────────────────────────────\n","# Embedding helper\n","# ─────────────────────────────────────────────\n","def embed_text(text: str) -> np.ndarray:\n","    resp = openai.embeddings.create(input=text, model=OPEN_AI_MODEL)\n","    return np.array(resp.data[0].embedding, dtype=np.float32)\n","\n","# ─────────────────────────────────────────────\n","# Combine embedding (amount + merchant + location)\n","# ─────────────────────────────────────────────\n","W_AMOUNT, W_MERCHANT, W_LOCATION = 0.2, 0.3, 0.5\n","\n","def normalize_amount(amount: float, lo: float, hi: float) -> float:\n","    span = max(hi - lo, 1e-6)\n","    return float(np.clip((amount - lo) / span, 0.0, 1.0))\n","\n","def make_embedding(merchant: str, location: str, amount: float, lo: float, hi: float) -> list:\n","    amount_norm = normalize_amount(amount, lo, hi)\n","    a_vec = np.array([amount_norm], dtype=np.float32) * W_AMOUNT\n","    m_vec = embed_text(merchant) * W_MERCHANT\n","    l_vec = embed_text(location) * W_LOCATION\n","    combined = np.concatenate([a_vec, m_vec, l_vec]).astype(np.float32)\n","    norm = np.linalg.norm(combined)\n","    if norm > 0:\n","        combined /= norm\n","    return combined.tolist()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3572489Z","session_start_time":null,"execution_start_time":"2025-11-12T10:07:30.2128819Z","execution_finish_time":"2025-11-12T10:07:36.5392184Z","parent_msg_id":"92e1d5d5-9bd8-4865-bf3d-0f24a1398a38"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ed91b8dd-b083-4b58-9360-5a56d18ab34d"},{"cell_type":"markdown","source":["#### Combined Embedding: Amount + Merchant + Location\n","\n","Creates a single vector by combining a scaled **amount** feature with **merchant** and **location** embeddings, then **L2-normalizes** the result.\n","\n","**How it works**\n","- **normalize_amount** scales the transaction amount into **[0, 1]** using the **per-merchant** typical range lo..hi.\n","- **Weights** emphasize signal importance: amount (0.2), merchant (0.3), location (0.5).\n","- Concatenates [amount_scalar, merchant_embedding, location_embedding] and **L2-normalizes**.\n","\n","**Dimensionality note**\n","\n","- If your text embedding dimension is d, the final vector has size **1 + d + d**.\n","- Example: with 1536-dim embeddings → 3073 total dimensions.\n","- If you plan to **index** this vector in Cosmos DB vector indexing, ensure your **indexing policy** supports the dimension (or project down with PCA/UMAP, or use a single-text prompt like \"merchant, location, amount bucket\" to produce one embedding)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5e911c9a-d00f-43b9-bca1-166977bc329c"},{"cell_type":"code","source":["\n","# ─────────────────────────────────────────────\n","# Helpers for merchant profiles & sampling\n","# ─────────────────────────────────────────────\n","\n","def _random_spend_range_for_merchant(name: str) -> tuple[float, float]:\n","    \"\"\"\n","    Assign a min/max typical spend per merchant. You can tweak bands per category.\n","    For simplicity, use the merchant name to bucket into spend bands heuristically.\n","    \"\"\"\n","    n = name.lower()\n","    # Basic buckets by intuition—adjust as you like\n","    if any(k in n for k in [\"airlines\", \"delta\", \"united\", \"american\", \"southwest\", \"marriott\", \"hilton\", \"hyatt\", \"apple store\", \"microsoft\", \"samsung\", \"ikea\", \"cartier\", \"rolex\", \"gucci\", \"tiffany\", \"prada\", \"louis vuitton\"]):\n","        lo, hi = 120.0, 600.0\n","    elif any(k in n for k in [\"uber\", \"lyft\", \"starbucks\", \"dunkin\", \"taco bell\", \"kfc\", \"mcdonald\", \"burger king\", \"subway\", \"popeyes\", \"chipotle\", \"five guys\", \"shake shack\", \"panera\"]):\n","        lo, hi = 5.0, 35.0\n","    elif any(k in n for k in [\"walmart\", \"target\", \"costco\", \"kroger\", \"safeway\", \"publix\", \"albertsons\", \"trader joe\", \"whole foods\", \"cvs\", \"walgreens\", \"rite aid\"]):\n","        lo, hi = 20.0, 180.0\n","    elif any(k in n for k in [\"netflix\", \"hulu\", \"disney\", \"spotify\", \"prime video\", \"youtube premium\", \"hbo\", \"peacock\", \"paramount\", \"apple tv\"]):\n","        lo, hi = 5.0, 40.0\n","    else:\n","        lo, hi = 15.0, 250.0\n","\n","    \n","    # Add slight randomization per customer-merchant profile\n","    pad = random.uniform(-0.15, 0.15)  # ±15%\n","    width_scale = random.uniform(0.85, 1.20)\n","    lo = max(1.0, lo * (1.0 + pad))\n","    hi = max(lo + 5.0, hi * width_scale)\n","    return round(lo, 2), round(hi, 2)\n","\n","\n","def _triangular_amount(lo: float, hi: float) -> float:\n","    \"\"\"Sample an amount with more mass around the mid of [lo, hi].\"\"\"\n","    mid = (lo + hi) / 2.0\n","    return round(random.triangular(lo, hi, mid), 2)\n","\n","\n","def _pick_location(home_state: str, home_prob: float = 0.85) -> str:\n","    \"\"\"Return the home state with probability home_prob; otherwise a different random state.\"\"\"\n","    if random.random() < home_prob:\n","        return home_state\n","    else:\n","        # ensure it's different than home_state\n","        alt = home_state\n","        while alt == home_state:\n","            alt = random.choice(US_STATES)\n","        return alt\n","\n","\n","def build_customer_profile(available_merchants: list[str], available_states: list[str]) -> dict:\n","    \"\"\"\n","    Choose 3–5 merchants, and for each assign:\n","      - 'home_state'\n","      - 'lo', 'hi' spend band (per merchant)\n","    Returns: { merchant_name: {\"home_state\": str, \"lo\": float, \"hi\": float}, ... }\n","    \"\"\"\n","    k = random.randint(3, 5)\n","    chosen = random.sample(available_merchants, k)\n","    profile = {}\n","    for m in chosen:\n","        lo, hi = _random_spend_range_for_merchant(m)\n","        profile[m] = {\n","            \"home_state\": random.choice(available_states),\n","            \"lo\": lo,\n","            \"hi\": hi,\n","        }\n","    return profile\n","\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3586928Z","session_start_time":null,"execution_start_time":"2025-11-12T10:07:36.5412612Z","execution_finish_time":"2025-11-12T10:08:06.3303044Z","parent_msg_id":"dc135c86-7e9f-45cc-ada2-46754b757278"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8f4b26e4-864b-45ef-a527-92a36d76b357"},{"cell_type":"markdown","source":["**Insert a Single Transaction**\n","\n","Builds the transaction document (including the combined vector) and writes it to the CCTransactions container.\n","\n","**Document shape (transactions)**\n","\n","- id: unique UUID for the transaction.\n","- type: \"transaction\".\n","- card_id: credit-card identifier (used as **partition key** in the recommended model).\n","- customerId: owning customer.\n","- merchant, location, amount: observable features.\n","- embedding: combined vector for semantic similarity or anomaly detection.\n","- timestamp: server-side UTC ISO timestamp.\n","\n","\n","**Partitioning note**: This sample assumes **/card_id** as the partition key for transactions. Co-locating events for a single card simplifies per-card analytics."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"711a8554-4d0a-466a-ab39-e8da4a9d9daf"},{"cell_type":"code","source":["# ─────────────────────────────────────────────\n","# Generate and insert a transaction\n","# ─────────────────────────────────────────────\n","def add_transaction(card_id: str, customer_id: str, merchant: str, location: str,\n","                    amount: float, lo: float, hi: float):\n","    emb = make_embedding(merchant, location, amount, lo, hi)\n","    doc = {\n","        \"id\": str(uuid.uuid4()),\n","        \"type\": \"transaction\",\n","        \"card_id\": card_id,\n","        \"customer_id\": customer_id,\n","        \"merchant\": merchant,\n","        \"location\": location,\n","        \"amount\": amount,\n","        \"embedding\": emb,\n","        \"timestamp\": datetime.now(timezone.utc).isoformat()\n","    }\n","    txns_container.create_item(doc)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3603267Z","session_start_time":null,"execution_start_time":"2025-11-12T10:08:06.3330713Z","execution_finish_time":"2025-11-12T10:08:33.9807053Z","parent_msg_id":"3520e622-b306-43aa-9843-43f02af21457"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"08e0a621-5359-43a2-b15a-deb448c75443"},{"cell_type":"markdown","source":["**Credit Card Helpers & Factory**\n","\n","Produces **synthetic** but realistic-looking credit card items and identities to populate the CreditCards container.\n","\n","**Modeling assumptions**\n","- CreditCards uses partition key /card_id, matching the card_id you store in transactions for co-location by card.\n","- These values are synthetic and for sample/demo purposes only."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d9f64fa8-e47b-4680-8642-eb5f26be1df3"},{"cell_type":"code","source":["\n","# ─────────────────────────────────────────────\n","# Credit card helpers + factory (your function)\n","# ─────────────────────────────────────────────\n","\n","def synthetic_card_number(rng: random.Random) -> str:\n","    # 16 digit card number\n","    card_number = f\"{rng.randint(0,9999):04d}-{rng.randint(0,9999):04d}-{rng.randint(0,9999):04d}-{rng.randint(0,9999):04d}\"\n","    return card_number\n","\n","def synthetic_cvv(rng: random.Random) -> str:\n","    return f\"{rng.randint(0, 999):03d}\"\n","\n","def synthetic_expiration_date(rng: random.Random) -> str:\n","    expiration_date = f\"{rng.randint(1, 12):02d}/{datetime.now().year + rng.randint(1, 5)}\"\n","    return expiration_date\n","\n","def create_credit_card(customer_id: str, card_id: str, rng: random.Random) -> Dict:\n","    return {\n","        \"id\": card_id,            # item id in CreditCards\n","        \"type\": \"card\",\n","        \"card_id\": card_id,        # PK (assumes /card_id partition key on CreditCards)\n","        \"customer_id\": customer_id,\n","        \"card_number\": synthetic_card_number(rng),  # synthetic\n","        \"security_code\": synthetic_cvv(rng),          # '000'..'999'\n","        \"expiration_date\": synthetic_expiration_date(rng),\n","        \"status\": \"unlocked\",\n","        \"last_lock_reason\": \"\",  # no lock reason\n","        \"last_updated\": datetime.now(timezone.utc).isoformat(),\n","        \"createdAt\": datetime.now(timezone.utc).isoformat()\n","    }\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"finished","queued_time":"2025-11-12T10:03:18.3617788Z","session_start_time":null,"execution_start_time":"2025-11-12T10:08:33.982988Z","execution_finish_time":"2025-11-12T10:08:53.2425428Z","parent_msg_id":"bca0a052-f65f-4096-8270-edc21c52dac4"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"39c4b03a-89a8-4ea6-aa03-15423d9c3a3a"},{"cell_type":"markdown","source":["**Bulk Generation: Customers, Cards, and Transactions**\n","\n","Creates a set of Customer_1..N, generates a card for each, and writes a stream of transactions per customer using the profile-driven distributions.\n","\n","**Behavior**\n","\n","- Generates limit_customers customers and 3–5 favorite merchants each.\n","- Produces up to max_txns_per_customer per customer (randomized 60–100% of the cap).\n","- Skews locations toward a home state with probability home_prob (default 0.85).\n","- Uses sleep_between to throttle writes if needed (RU rate-limiting or embedding throughput).\n","- seed makes the generation deterministic for reproducibility.\n","- timestamp_spread_days is accepted for future enhancement (e.g., post-insert timestamp adjustments)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"41b30d24-4ca2-40e3-8fb3-019003005b4c"},{"cell_type":"code","source":["\n","\n","# ─────────────────────────────────────────────\n","# Main: create customers & cards, then generate txns\n","# ─────────────────────────────────────────────\n","\n","def generate_new_customers_and_transactions(limit_customers: int = 10,\n","                                            max_txns_per_customer: int = 100,\n","                                            home_prob: float = 0.85,\n","                                            sleep_between: float = 0.0,\n","                                            seed: int | None = 42,\n","                                            timestamp_spread_days: int | None = None):\n","    \"\"\"\n","    Creates Customers_1..N and their cards, inserts cards into CreditCards container,\n","    then generates transactions for each new card using your add_transaction function.\n","\n","    Args:\n","      limit_customers: number of customers to create (Customer_1..Customer_N)\n","      max_txns_per_customer: cap per customer (actual n is [60%, 100%] of cap)\n","      home_prob: probability a txn occurs in the merchant home state\n","      sleep_between: sleep (secs) between inserts to ease RU throttling\n","      seed: seed for deterministic synthetic data (None for non-deterministic)\n","      timestamp_spread_days: if set, randomly distribute timestamps across the past N days\n","                             instead of using \"now()\" in add_transaction. (We’ll override after insert)\n","    \"\"\"\n","    rng = random.Random(seed) if seed is not None else random.Random()\n","\n","    total_cards = 0\n","    total_written = 0\n","\n","    \n","    for i in range(1, limit_customers + 1):\n","        customer_id = f\"U{i:04d}\"\n","        card_id = f\"C{i:04d}\"\n","        card_doc = create_credit_card(customer_id, card_id, rng)\n","\n","        # Insert card first\n","        try:\n","            cards_container.create_item(card_doc)\n","            total_cards += 1\n","        except Exception as e:\n","            print(f\"[WARN] Failed to create card {card_id} for {customer_id}: {e}\")\n","            continue\n","\n","        # Build per-customer profile\n","        profile = build_customer_profile(merchants, US_STATES)\n","        m_names = list(profile.keys())\n","\n","        # Decide how many transactions to generate for this customer\n","        n = rng.randint(max(1, math.ceil(max_txns_per_customer * 0.6)), max_txns_per_customer)\n","\n","        # Generate transactions\n","        for _ in range(n):\n","            m = rng.choice(m_names)\n","            home_state = profile[m][\"home_state\"]\n","            lo = profile[m][\"lo\"]; hi = profile[m][\"hi\"]\n","            amount = _triangular_amount(lo, hi)\n","            location = _pick_location(home_state, home_prob=home_prob)\n","\n","            try:\n","\n","                \n","                # Insert using your existing add_transaction (uses \"now\" internally)\n","                add_transaction(\n","                    card_id=card_id,\n","                    customer_id=customer_id,\n","                    merchant=m,\n","                    location=location,\n","                    amount=amount,\n","                    lo=lo,\n","                    hi=hi\n","                )\n","                total_written += 1\n","            except Exception as e:\n","                print(f\"[WARN] Failed to add txn for {customer_id} ({customer_id + '_card'}), merchant={m}: {e}\")\n","                continue\n","\n","            if sleep_between > 0:\n","                time.sleep(sleep_between)\n","\n","\n","\n","# Generate Transactions\n","generate_new_customers_and_transactions(max_txns_per_customer=100, limit_customers=100)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"submitted","livy_statement_state":"running","session_id":"3943108c-ce8a-4404-90cb-147cdcdae074","normalized_state":"running","queued_time":"2025-11-12T10:03:18.3631381Z","session_start_time":null,"execution_start_time":"2025-11-12T10:08:53.2447917Z","execution_finish_time":null,"parent_msg_id":"4a05fc1c-1cec-4903-89ab-1aa5fd584187"},"text/plain":"StatementMeta(, 3943108c-ce8a-4404-90cb-147cdcdae074, 18, Submitted, Running, Running)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d2a51901-31f9-4b9e-99b6-ba3211bbee52"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","language":null,"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":null}},"nbformat":4,"nbformat_minor":5}