{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8d2ce6-cb92-4b24-abab-f839300dc2fa",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Cosmos DB in Fabric\n",
    "\n",
    "## Advanced Vector Search\n",
    "\n",
    "### With deployed Azure OpenAI custom model and Azure Key Vault\n",
    "\n",
    "This sample notebook shows how to do a vector search for Cosmos DB in Fabric using Azure OpenAI directly with a custom embedding model.\n",
    "\n",
    "*This is an advanced sample that requires Azure Subscription Owner rights.*\n",
    "\n",
    "### Features of this Notebook\n",
    "This notebook demonstrates the following concepts:\n",
    "\n",
    "- How to write a query in Cosmos DB in Fabric to perform a vector similarity search\n",
    "- How to use the similarity score from a Cosmos DB vector search to filter and sort for the best results\n",
    "- How to generate embeddings using OpenAI embeddings model with custom dimension size\n",
    "- How to deploy Azure OpenAI with models and Azure Key Vault to store secrets\n",
    "- How to authenticate to Azure Open AI using keys from Azure Key Vault\n",
    "- How to create and configure a new Cosmos DB container with vector indexing\n",
    "\n",
    "\n",
    "This sample uses the [Fabric, KeyVault & OpenAI Sample on Github](https://github.com/AzureCosmosDB/fabric-keyvault-openai-secrets) sample to automatically provision an Azure KeyVault and Azure OpenAI account and models. It also applies Azure RBAC policies using your Entra ID as well as the Workspace Identity for your Fabric Workspace. Follow the instructions in the repo and copy the output values directly in the cell below.\n",
    "\n",
    "This sample uses a custom product catalog dataset [fabricSampleDataVectors-3-large-512.json](https://github.com/AzureCosmosDB/cosmos-fabric-samples/blob/main/datasets/fabricSampleDataVectors-3-large-512.json) with embeddings generated using the text-3-large model and 512 dimensions.\n",
    "\n",
    "This sample demonstrates using fewer dimensions in your data. This reduces the size of the data which can help to optimize performance, but it comes at the cost of reduced accuracy in your vector search results.\n",
    "\n",
    "Requirements:\n",
    "- Azure Subscription Owner permissions\n",
    "- Workspace identity configured for your Fabric workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2f3f7-fb8d-440b-9169-eadc015e6a26",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Install packages\n",
    "%pip install azure-cosmos\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e051f6-1163-4662-ad68-d705033d374d",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Imports and config values\n",
    "import logging\n",
    "from rich.pretty import pprint\n",
    "import json\n",
    "import requests\n",
    "import notebookutils\n",
    "from typing import Optional, List, Dict, Any\n",
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.cosmos import PartitionKey, exceptions, ThroughputProperties\n",
    "from openai.lib.azure import AsyncAzureOpenAI\n",
    "\n",
    "# Values copied from the output when deploying the Fabric Keyvault OpenAI sample\n",
    "KEYVAULT_URI=\"https://your-keyvault-account.vault.azure.net/\"\n",
    "KEYVAULT_OPENAI_ENDPOINT=\"openai-endpoint\"\n",
    "KEYVAULT_OPENAI_API_KEY=\"openai-api-key\"\n",
    "OPENAI_GPT_MODEL=\"gpt-4.1-mini\"\n",
    "OPENAI_EMBEDDING_MODEL=\"text-embedding-3-large\"\n",
    "\n",
    "OPENAI_ENDPOINT = notebookutils.credentials.getSecret(KEYVAULT_URI, KEYVAULT_OPENAI_ENDPOINT)\n",
    "OPENAI_KEY = notebookutils.credentials.getSecret(KEYVAULT_URI, KEYVAULT_OPENAI_API_KEY)\n",
    "OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "OPENAI_EMBEDDING_DIMENSIONS = 512\n",
    "\n",
    "COSMOS_ENDPOINT = 'https://my-cosmos-endpoint.cosmos.fabric.microsoft.com:443/'\n",
    "COSMOS_DATABASE_NAME = '{your-cosmos-artifact-name}'\n",
    "COSMOS_CONTAINER_NAME = 'SampleVectorData-text3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925add8-3777-4e67-9f1a-dc5de34d9150",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Custom TokenCredential implementation for Fabric authentication\n",
    "%pip install azure-core\n",
    "from azure.core.credentials import TokenCredential, AccessToken\n",
    "import base64\n",
    "import notebookutils\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "class FabricTokenCredential(TokenCredential):\n",
    "\n",
    "    def get_token(self, *scopes: str, claims: Optional[str] = None, tenant_id: Optional[str] = None,\n",
    "                  enable_cae: bool = False, **kwargs: Any) -> AccessToken:\n",
    "        access_token = notebookutils.credentials.getToken(\"https://cosmos.azure.com/\")\n",
    "        parts = access_token.split(\".\")\n",
    "        if len(parts) < 2:\n",
    "            raise ValueError(\"Invalid JWT format\")\n",
    "        payload_b64 = parts[1]\n",
    "        # Fix padding\n",
    "        padding = (-len(payload_b64)) % 4\n",
    "        if padding:\n",
    "            payload_b64 += \"=\" * padding\n",
    "        payload_json = base64.urlsafe_b64decode(payload_b64.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        payload = json.loads(payload_json)\n",
    "        exp = payload.get(\"exp\")\n",
    "        if exp is None:\n",
    "            raise ValueError(\"exp claim missing in token\")\n",
    "        return AccessToken(token=access_token, expires_on=exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e4039-c86f-4ce2-a464-f158ee1bcf80",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Azure OpenAI client using keys from KeyVault\n",
    "OPENAI_CLIENT = AsyncAzureOpenAI(\n",
    "    api_version=OPENAI_API_VERSION,\n",
    "    azure_endpoint=OPENAI_ENDPOINT,\n",
    "    api_key=OPENAI_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737bd4b-f201-4e0a-822f-661f3a5fb2c8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Cosmos DB client and database\n",
    "COSMOS_CLIENT = CosmosClient(COSMOS_ENDPOINT, FabricTokenCredential())\n",
    "DATABASE = COSMOS_CLIENT.get_database_client(COSMOS_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c8e96-c460-45db-aae7-a384711cf760",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Creates and configure a container for vector indexing and load sample data\n",
    "# This container is specifically configured for 512 dimensions\n",
    "# Vectors generated using text-3-large model with 512 dimensions\n",
    "async def create_container_and_load_data():\n",
    "    \n",
    "    # Define the vector policy for the container\n",
    "    vector_embedding_policy = {\n",
    "        \"vectorEmbeddings\": [\n",
    "            {\n",
    "                \"path\":\"/vectors\",\n",
    "                \"dataType\":\"float32\",\n",
    "                \"distanceFunction\":\"cosine\",\n",
    "                \"dimensions\":512\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Define the indexing policy for the container\n",
    "    indexing_policy = {\n",
    "        \"includedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/*\"\n",
    "            }\n",
    "        ],\n",
    "        \"excludedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/vectors/*\"\n",
    "            },\n",
    "            {\n",
    "                \"path\": \"/\\\"_etag\\\"/?\"\n",
    "            }\n",
    "        ],\n",
    "        \"vectorIndexes\": [\n",
    "            {\n",
    "                \"path\": \"/vectors\",\n",
    "                \"type\": \"quantizedFlat\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Create the vectorized sample product container\n",
    "    CONTAINER = await DATABASE.create_container_if_not_exists(\n",
    "        id=COSMOS_CONTAINER_NAME,\n",
    "        partition_key=PartitionKey(path='/categoryName', kind='Hash'),\n",
    "        indexing_policy=indexing_policy,\n",
    "        vector_embedding_policy=vector_embedding_policy,\n",
    "        offer_throughput=ThroughputProperties(auto_scale_max_throughput=5000))\n",
    "\n",
    "    print(\"Container created. Loading products\")\n",
    "\n",
    "    # Load the vectorized product data. Vectors generated using text-3-large model with 512 dimensions\n",
    "    url = \"https://raw.githubusercontent.com/AzureCosmosDB/cosmos-fabric-samples/refs/heads/main/datasets/fabricSampleDataVectors-3-large-512.json\"\n",
    "    data = requests.get(url).json()\n",
    "    \n",
    "    # Insert the data into the container\n",
    "    for item in data:\n",
    "        await CONTAINER.create_item(item)\n",
    "\n",
    "    print(f\"Products loaded\")\n",
    "\n",
    "    return CONTAINER\n",
    "\n",
    "# Run the function and get the container reference\n",
    "CONTAINER = await create_container_and_load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe4be3-4ab2-4b23-9f60-72a669c328ca",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Define function to generate embeddings for vector search\n",
    "async def generate_embeddings(text):\n",
    "\n",
    "    response = await OPENAI_CLIENT.embeddings.create(\n",
    "        input=text,\n",
    "        model=OPENAI_EMBEDDING_MODEL,\n",
    "        dimensions=OPENAI_EMBEDDING_DIMENSIONS\n",
    "    )\n",
    "    \n",
    "    embeddings = response.model_dump()\n",
    "    return embeddings['data'][0]['embedding']\n",
    "\n",
    "# Test Fabric's OpenAI model\n",
    "#search_text = \"Hello from Fabric Notebooks\"\n",
    "#embeddings = await generate_embeddings(search_text.strip())\n",
    "#print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416c25e-1a47-42d7-9ac5-6c4c91077c88",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Define function to perform vector search\n",
    "async def search_products(search_text: str, similarity: float = 0.8, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "\n",
    "    try:\n",
    "        # Generate embeddings for the search text\n",
    "        embeddings = await generate_embeddings(search_text.strip())\n",
    "\n",
    "        # Cosmos query with VectorDistance to perform similarity search\n",
    "        query = \"\"\"\n",
    "            SELECT TOP @limit \n",
    "                VectorDistance(c.vectors, @embeddings) AS SimilarityScore,\n",
    "                c.name, \n",
    "                c.description,\n",
    "                c.categoryName,\n",
    "                c.currentPrice,\n",
    "                c.inventory,\n",
    "                c.priceHistory\n",
    "            FROM c \n",
    "            WHERE \n",
    "                c.docType = @docType AND\n",
    "                VectorDistance(c.vectors, @embeddings) >= @similarity\n",
    "            ORDER BY \n",
    "                VectorDistance(c.vectors, @embeddings)\n",
    "        \"\"\"\n",
    "\n",
    "        parameters = [\n",
    "            {\"name\": \"@limit\", \"value\": limit},\n",
    "            {\"name\": \"@embeddings\", \"value\": embeddings},\n",
    "            {\"name\": \"@docType\", \"value\": \"product\"},\n",
    "            {\"name\": \"@similarity\", \"value\": similarity}\n",
    "        ]\n",
    "\n",
    "        # Async query: gather results into a list\n",
    "        products = [p async for p in CONTAINER.query_items(\n",
    "            query=query,\n",
    "            #enable_cross_partition_query=True,\n",
    "            parameters=parameters\n",
    "        )]\n",
    "\n",
    "        # Remove the vectors property if it appears, unnecessarily large\n",
    "        for p in products:\n",
    "            p.pop('vectors', None)\n",
    "\n",
    "        return products\n",
    "        \n",
    "    except exceptions.CosmosHttpResponseError as e:\n",
    "        logging.error(f\"Cosmos DB query failed: {e}\")\n",
    "        raise\n",
    "    except Exceptions as e:\n",
    "        logging.error(f\"Unexpected error in search_products: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7a6f92-a017-4ba8-91d8-d7478b1ddd35",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Vector Search for products\n",
    "# The value for similarity score returns 8 products, the limit will restrict the results to 5\n",
    "# Feel free to adjust these to see how the results change. \n",
    "# You can also modify the search text for different results\n",
    "products = await search_products(search_text=\"gaming pc\", similarity=0.628, limit=5)\n",
    "\n",
    "#print the number of products found\n",
    "print(f\"Found {len(products)} products matching the search criteria.\")\n",
    "\n",
    "display(products) # for tabular output\n",
    "pprint(products) #Json friendly output"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "environment": {
    "environmentId": "d617f2b6-1962-435f-a865-7652c09a1e9b",
    "workspaceId": "851f2673-aeb7-4b55-b663-82c63a597e07"
   },
   "lakehouse": null
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "language": null,
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "43200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
