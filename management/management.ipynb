{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a460598-d5dc-4aca-8ec4-e5e012527fd6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Cosmos DB in Fabric\n",
    "\n",
    "## Management Operations\n",
    "\n",
    "This sample notebook shows how to common management tasks with Cosmos DB in Fabric containers.\n",
    "\n",
    "### Features of this Notebook\n",
    "This notebook demonstrates the following concepts:\n",
    "\n",
    "- How to define indexing and vector policies for a container\n",
    "- How to create a simple container with autoscale throughput\n",
    "- How to create a container with vector indexing\n",
    "- How to load data with retries on 429 errors\n",
    "- How to read and update container throughput\n",
    "\n",
    "Requirements:\n",
    "- This sample requires creating a Cosmos DB artifact in your Fabric Workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282ffb0-629e-4723-8603-53703ed21d25",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Install packages\n",
    "%pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34718b-b954-4748-971f-15cd22af3e7d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Imports and config values\n",
    "import logging\n",
    "import requests\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "from azure.cosmos.aio import CosmosClient, ContainerProxy\n",
    "from azure.cosmos import PartitionKey, ThroughputProperties\n",
    "from azure.cosmos.exceptions import CosmosHttpResponseError, CosmosResourceNotFoundError\n",
    "\n",
    "COSMOS_ENDPOINT = '{https://my-cosmos-endpoint.cosmos.fabric.microsoft.com:443/}'\n",
    "COSMOS_DATABASE_NAME = '{your-cosmos-artifact-name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd8949-6d75-41fe-8b6d-ddfa168f75c1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Custom TokenCredential implementation for authentication in a Fabric Notebook\n",
    "%pip install azure-core\n",
    "from azure.core.credentials import TokenCredential, AccessToken\n",
    "import base64\n",
    "import json\n",
    "import notebookutils\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "class FabricTokenCredential(TokenCredential):\n",
    "\n",
    "    def get_token(self, *scopes: str, claims: Optional[str] = None, tenant_id: Optional[str] = None,\n",
    "                  enable_cae: bool = False, **kwargs: Any) -> AccessToken:\n",
    "        access_token = notebookutils.credentials.getToken(\"https://cosmos.azure.com/\")\n",
    "        parts = access_token.split(\".\")\n",
    "        if len(parts) < 2:\n",
    "            raise ValueError(\"Invalid JWT format\")\n",
    "        payload_b64 = parts[1]\n",
    "        # Fix padding\n",
    "        padding = (-len(payload_b64)) % 4\n",
    "        if padding:\n",
    "            payload_b64 += \"=\" * padding\n",
    "        payload_json = base64.urlsafe_b64decode(payload_b64.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        payload = json.loads(payload_json)\n",
    "        exp = payload.get(\"exp\")\n",
    "        if exp is None:\n",
    "            raise ValueError(\"exp claim missing in token\")\n",
    "        return AccessToken(token=access_token, expires_on=exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e756765-5d0f-4237-89fe-d490f8d15c33",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Cosmos DB client and database\n",
    "COSMOS_CLIENT = CosmosClient(COSMOS_ENDPOINT, FabricTokenCredential())\n",
    "DATABASE = COSMOS_CLIENT.get_database_client(COSMOS_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21911e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the product data with retry logic for 429 errors\n",
    "async def load_data(url: str, container: ContainerProxy):\n",
    "    data = requests.get(url).json()\n",
    "\n",
    "    i = 0\n",
    "    # Insert the data into the container with retry logic for 429 errors\n",
    "    for item in data:\n",
    "        retry_count = 0\n",
    "        max_retries = 5\n",
    "        \n",
    "        while retry_count <= max_retries:\n",
    "            try:\n",
    "                await container.create_item(item)\n",
    "                i += 1\n",
    "                break  # Success, move to next item\n",
    "                \n",
    "            except CosmosHttpResponseError as e:\n",
    "                if e.status_code == 429:  # Rate limited\n",
    "                    retry_count += 1\n",
    "                    if retry_count > max_retries:\n",
    "                        print(f\"Max retries exceeded for item {i}. Skipping.\")\n",
    "                        break\n",
    "                    \n",
    "                    # Extract retry-after-ms from response headers\n",
    "                    retry_after_ms = e.headers.get('x-ms-retry-after-ms', '1000')\n",
    "                    retry_after_seconds = int(retry_after_ms) / 1000.0\n",
    "                    \n",
    "                    print(f\"Rate limited (429). Retrying item {i} after {retry_after_seconds} seconds (attempt {retry_count}/{max_retries})\")\n",
    "                    await asyncio.sleep(retry_after_seconds)\n",
    "                else:\n",
    "                    # Other errors, re-raise\n",
    "                    print(f\"Error loading item {i}: {e}\")\n",
    "                    raise\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error loading item {i}: {e}\")\n",
    "                raise\n",
    "\n",
    "    print(f\"{i} Products loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and configure a container with parameters\n",
    "async def create_container_basic(containerName: str, partitionKey: str, throughput: int):\n",
    "\n",
    "    # Define the indexing policy for the container\n",
    "    indexing_policy: Dict[str, Any] = {\n",
    "        \"includedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/*\"\n",
    "            }\n",
    "        ],\n",
    "        \"excludedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/\\\"_etag\\\"/?\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Containers in Fabric portal are created with 5000 RU/s by default\n",
    "    # You can create containers via SDK with minimum of 1000 RU/s\n",
    "    CONTAINER = await DATABASE.create_container_if_not_exists(\n",
    "        id=containerName,\n",
    "        partition_key=PartitionKey(path=partitionKey, kind='Hash'),\n",
    "        indexing_policy=indexing_policy,\n",
    "        offer_throughput=ThroughputProperties(auto_scale_max_throughput=throughput))\n",
    "\n",
    "    print(f\"Container created\")\n",
    "    return CONTAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the create_container_basic() function\n",
    "CONTAINER = await create_container_basic(containerName='SampleData', partitionKey='/categoryName', throughput=5000)\n",
    "\n",
    "# Load the sample data\n",
    "url = \"https://raw.githubusercontent.com/AzureCosmosDB/cosmos-fabric-samples/refs/heads/main/datasets/fabricSampleDatajson\"\n",
    "await load_data(url, CONTAINER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb491148-74b1-43cd-a9b0-4a65bfd0d8d6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Creates and configure a container for vector indexing with parameters\n",
    "async def create_sample_vector_data_container(containerName: str,partitionKey: str, throughput: int, dimensions: int):\n",
    "    \n",
    "    # Define the vector policy for the container\n",
    "    vector_embedding_policy: Dict[str, Any] = {\n",
    "        \"vectorEmbeddings\": [\n",
    "            {\n",
    "                \"path\":\"/vectors\",\n",
    "                \"dataType\":\"float32\",\n",
    "                \"distanceFunction\":\"cosine\",\n",
    "                \"dimensions\":dimensions\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Define the indexing policy for the container\n",
    "    indexing_policy: Dict[str, Any] = {\n",
    "        \"includedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/*\"\n",
    "            }\n",
    "        ],\n",
    "        \"excludedPaths\": [\n",
    "            {\n",
    "                \"path\": \"/vectors/*\"\n",
    "            },\n",
    "            {\n",
    "                \"path\": \"/\\\"_etag\\\"/?\"\n",
    "            }\n",
    "        ],\n",
    "        \"vectorIndexes\": [\n",
    "            {\n",
    "                \"path\": \"/vectors\",\n",
    "                \"type\": \"quantizedFlat\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Containers in Fabric portal are created with 5000 RU/s by default\n",
    "    # You can create containers via SDK with minimum of 1000 RU/s\n",
    "    # Create the vectorized sample product container with 1000 RU/s\n",
    "    CONTAINER = await DATABASE.create_container_if_not_exists(\n",
    "        id=containerName,\n",
    "        partition_key=PartitionKey(path=partitionKey, kind='Hash'),\n",
    "        indexing_policy=indexing_policy,\n",
    "        vector_embedding_policy=vector_embedding_policy,\n",
    "        offer_throughput=ThroughputProperties(auto_scale_max_throughput=throughput))\n",
    "\n",
    "    print(f\"Container created\")\n",
    "    return CONTAINER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the create_sample_vector_data_container() function\n",
    "# with a vector container policy for 1536 dimensions\n",
    "# and a vector indexing policy on /vectors property\n",
    "CONTAINER = await create_sample_vector_data_container(containerName='SampleVectorData', partitionKey='/categoryName', throughput=5000, dimensions=1536)\n",
    "\n",
    "# Load the vectorized sample data with ADA-002 vectors with 1536 dimensions\n",
    "url = \"https://raw.githubusercontent.com/AzureCosmosDB/cosmos-fabric-samples/refs/heads/main/datasets/fabricSampleDataVectors-ada-002-1536.json\"\n",
    "await load_data(url, CONTAINER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd435c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the create_sample_vector_data_container() function\n",
    "# with a vector container policy for 1536 dimensions\n",
    "# and a vector indexing policy on /vectors property\n",
    "CONTAINER = await create_sample_vector_data_container(containerName='SampleVectorDataText3', partitionKey='/categoryName', throughput=1000, dimensions=512)\n",
    "\n",
    "# Load the vectorized sample data with text-3-large vectors with 512 dimensions\n",
    "url = \"https://raw.githubusercontent.com/AzureCosmosDB/cosmos-fabric-samples/refs/heads/main/datasets/fabricSampleDataVectors-3-large-512.json\"\n",
    "await load_data(url, CONTAINER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb099c-d2be-4e0d-86b5-d0c262aa2a11",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Get the current throughput properties on a container and increase it by 1000 RU/s\n",
    "throughput_properties = await CONTAINER.get_throughput()\n",
    "autoscale_throughput = throughput_properties.auto_scale_max_throughput\n",
    "\n",
    "print(f\"Autoscale throughput: {autoscale_throughput}\")\n",
    "\n",
    "# Add 1000 RU to the current value\n",
    "new_throughput = autoscale_throughput + 1000\n",
    "\n",
    "await CONTAINER.replace_throughput(ThroughputProperties(auto_scale_max_throughput=new_throughput))\n",
    "\n",
    "# Verify the updated throughput\n",
    "updated_throughput_properties = await CONTAINER.get_throughput()\n",
    "print(f\"Verified updated autoscale throughput: {updated_throughput_properties.auto_scale_max_throughput}\")\n"
   ]
  }
 ],
 "metadata": {
  "a365ComputeOptions": null,
  "dependencies": {
   "lakehouse": null
  },
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "sessionKeepAliveTimeout": 0,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "43200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
